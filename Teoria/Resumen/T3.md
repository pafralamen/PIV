# Segmentación

Se basa en subdividir la imagen en una serie de regiones que comparten alguna característica común (misma textura o color, ser el mismo objeto...)

# Paradigmas de Segmentación

## Discontinuidad

Detectar cambios bruscos en el valor de los píxeles = <u>Fronteras</u>

## Similaridad

Agrupación conexa de píxeles con valores similares = <u>Regiones</u>

## Proceso de Segmentación

Siendo R el conjunto de píxeles de una imagen y Q un predicado aplicable a cualquier Ri. Se puede segmentar R en regiones Ri ⊆ R si cumplen:

**a)** U Ri = R
	`Cubra toda la imagen`
**b)** Ri es conjunto conexo para toda i
	`Cada región sea Conexa`
**c)** Ri ∩ Rj = ∅ si i != j
	`Regiones Disjuntas`
**d)** Q(Ri) = Verdad para todo Ri
	`Predicado que cumple una región, válido para toda ella`
**e)** Q(Ri U Rj) = Falso para regiones adyacentes
	`Para regiones adyacentes no se cumple el predicado`

<u>Predicado</u> = Algo calculable que devuelva V o F sobre un conjunto de píxeles

## Segmentación Basada en Fronteras

### Procesamiento Local

Un detector etiqueta los puntos frontera y se enlazan los que sean similares según los criterios:
`Dado un Entorno Sxy de (x,y), se considera que un punto (s, t) ∈ Sxy es similar a (x,y) si:`
`|M(s, t) − M(x, y)| ≤ ε, siendo M la Magnitud del gradiente y ε un umbral`
`|α(s, t) − α(x, y)| ≤ ε, siendo α el Ángulo del gradiente y ε un umbral`

### Enlazado de Fronteras

Siendo Tm - Umbral de magnitud /  A - Ángulo / Ta - Umbral de ángulo
· Se crea una imagen binaria con los puntos: `M(x, y) ≥ Tm y α(x, y) = A ± Ta`
· Se recorre la imagen por filas rellenando los huecos más cortos que un umbral

**[ Útil para reconocer el contorno de una Matrícula o Imágenes con Fronteras predominantes en una dirección ]**

### Procesamiento a Nivel de Región

#### Aproximación Poligonal Conjunto Puntos (Douglas-Peucker)

Partiendo de un conjunto de puntos ordenados en el que se conocen los extremos A y B:
1. Unir los extremos A,B en una frontera provisional
2. Trazar perpendiculares a la frontera uniendo el resto de puntos
3. Unir el punto que esté más alejado
4. Repetir pasos 2-3
5. Cuando los puntos restantes estén más cerca de la frontera que un umbral se para

**[Útil si es una curva abierta, en caso de ser cerrada se eligen dos puntos como extremos]**

#### Enlazado de Píxeles sin Información Regional

Si no tenemos información acerca de dónde están las regiones de interés se deben utilizar propiedades globales

##### Transformada de Hough

1. Por un punto (x,y) pasan infinitas rectas del tipo `y = ax + b`
2. Escribiendo la Ecc. como `b = -ax + y`, cada punto (x,y) genera una recta en el plano (a,b)
3. Dos puntos en (x,y) generan dos rectas en (a,b), que se cortan en el punto de (a,b) cuyos parámetros son los de la recta que une los puntos de (x,y)
4. Se buscan en (a,b) los puntos donde se acumulan muchas rectas. Esos puntos corresponden a rectas en (x,y) que pasan por muchos puntos frontera

<u>Problema:</u>
· Si una recta se aproxima a la vertical su pendiente tiende a Infinito => Representación Angular
  Así los puntos generan curvas sinusoidales en lugar de rectas

Este método se puede generalizar a cualquier función `g(v,c) = 0` con con un vector de coord y otro de coeficientes.
Cuanto más compleja sea la forma a detectar, más espacio de almacenamiento ocupa.

## Umbralización

### Segmentación por Umbralización

En función de un umbral se asignan los píxeles de una a imagen a una clase u otra

<u>Problema:</u> Al aumentar el ruido, las modas del histograma se mezclan

### Umbralización Global (Iterativo)

1. Seleccionar umbral inicial T
2. Segmentar la imagen con ese umbral. G1 < T y G2 el resto
3. Calcular la media de G1 y G2 para actualizar el umbral: `T = (m1+m2)/2`
4. Repetir pasos 2-3 hasta que se estabilice

Funciona siempre que el umbral inicial esté dentro de las modas

### Umbralización Otsu (Directo)

Se basa en minimizar el error medio que se comete al segmentar la imagen
· Partiendo de una imagen generada por dos distribuciones gaussianas (Tonos de gris)
· Busca el umbral donde, al superponer las distribuciones, la suma de los errores de cada una es mínima

Permite evaluar la separabilidad de las modas del histograma

#### Problemas Umbralización Otsu

- <u>Imagen con ruido</u> -> Histograma más homogéneo
	Solución: Suavizar (filtro paso bajo)
- <u>Objetos pequeños</u> -> Descompensan el histograma
	Solución: Crear máscara binaria a partir de la magnitud de gradiente de la imagen
	Así solo se cogen los píxeles a la frontera (donde la magnitud del gradiente aumenta)

### Umbralización Variable

Útil si la iluminación es variable

- Particionando en losetas la imagen
- Calcular umbral de cada punto en base a su entorno

## Segmentación Basada en Regiones

### Crecimiento de Regiones

Se asigna una etiqueta a un pixel si cumple determinada condición y tiene algún vecino que también la cumpla o ya forme parte de esa región:
1. Comienza con varias semillas (puntos iniciales de cada región)
2. Se van añadiendo a cada región los vecinos que cumplan las condiciones

Se trata de poner las semillas donde sepamos que hay una región de interés o tomando los centroides de cada posible región

#### Algoritmo

1. Partiendo del array de semillas S(x,y), se erosiona hasta que cada componente conexa sea de 1 pixel
2. Formar una imagen F que valga 1 en los puntos que cumplan el predicado
3. Formar una imagen G añadiendo cada punto que esté 8-conectado con algún punto semilla o que haya sido marcado y cumpla el predicado
4. Etiquetar cada componente conexa en G

### Partición y Mezcla

Subdividir la imagen en cuadrantes hasta que todos los píxeles de una región sean homogéneos respecto al predicado. Si hay dos regiones adyacentes con igual resultado del predicado se mezclan

**[Útil para detectar zonas con propiedades estadísticas determinadas]

### Inundación

- Genera resultados estables y fronteras cerradas
- Proporciona un marco para añadir restricciones basadas en conocimiento previo de la imagen

#### Fundamentos

- Tratar la imagen como una superficie 3D, donde la altura de un pixel es la magnitud de su gradiente. Así, los puntos más altos serán posibles fronteras

- Cada punto de la imagen pertenece a una clase:

  1. Mínimo Local
  2. Punto donde al dejar caer una gota -> 1 Mínimo Local concreto (Cuenca)
  3. Punto donde al dejar caer una gota -> +1 Mínimo Local (Línea Divisoria)

#### Algoritmo

1. La superficie 3D se inunda de manera uniforme
2. Cuando se van a unir dos cuencas, se coloca un muro (presa) para evitarlo
3. Al inundar toda la imagen, solo se ven las presas, correspondientes con las Fronteras
4. Las "islas" intermedias no corresponden a una frontera entre dos regiones, se descartan

#### Marcadores

- Debido a irregularidades del gradiente o ruido -> Sobresegmentación -> Necesario conocimiento adicional para limitar el nº de regiones

**Marcador**: Componente conexo de una imagen (parche)
	- Internos: Asociados a objetos
	- Externos: Asociados al fondo

##### Generación de Marcadores

- Preprocesamiento:
  Suavizado a la magnitud del gradiente (Elimina mínimos locales poco significativos y ruido)
- Criterios a Cumplir:
  - <u>Marcadores Internos</u>: Regiones cuyos alrededores tengan valores claramente más altos, que sean cerradas y con altura parecida
  - <u>Marcadores Externos:</u> Al inundar solamente los marcadores internos, el agua desbordará hasta cruzarse con el agua proveniente de otro marcador interno. Esa frontera delimita el marcador externo

- Cada región tiene una Zona de Interés + Porción de Fondo -> Inundando estas regiones por separado se obtienen las Fronteras Finales

**[ Utilidad Técnicas sin Información Adicional = Control Industrial, Astronomía, Biología ]**

# Clasificación y Reconocimiento

**Patrón:** Conjunto de descriptores organizados de una manera determinada

**Reconocimiento:**
Trata de deducir determinados elementos en la escena a partir de patrones detectados en la imagen.
Combina información a priori con evidencias extraídas de las imágenes

## Proceso de Reconocimiento

**Sistema de Reconocimiento:**

- Caracteriza todos los posibles patrones asociados a un fenómeno u objeto
- Dado un patrón observado: Reconoce si está presente y lo Clasifica en una categoría
- Esquema General:
	- Extraer características de la imagen y Obtener una representación de éstas
	- Construir un clasificador a partir de ejemplos conocidos y clasificar nuevas muestras

## Clasificación Bayesiana

Suponiendo que el objeto a clasificar está en la imagen, qué probabilidad hay de que la clasificación sea correcta
<img src="C:\Users\Pablo\Desktop\PIV\Capturas\clasificacionBayes.jpg" style="zoom: 67%;" />

· Si no se tiene conocimiento previo -> Todas las hipótesis equiprobables
· Si se tiene conocimiento previo -> Cierta hipótesis tendrá mayor probabilidad

Calcular probabilidad de todas las hipótesis es costoso -> Hipótesis MAP (Hipótesis más probable)

### Construcción de Reconocedor/Clasificador

1. Escoger un modelo en base a lo que Espero ver y lo que Veo
   (red neuronal, red bayesiana, vecinos cercanos...)
2. Instanciar el modelo (Aprendizaje):
	- Datos de Entrenamiento (Etiquetados)
	- Datos de Control (Para validar el modelo)
3. Aplicar el modelo a unos datos de prueba y comprobar la Capacidad de Generalización

## Detección de Caras (Características Simples en Cascada)

### Detector de Cascadas de Haar (Viola y Jones)

- Detecta la presencia de caras pero No Clasifica
- Emplea características muy simples (Tiempo Real)
- Basado en Clasificadores débiles en Cascada
- No tolera bien que las caras no estén bien orientadas
- No sabe dónde está la cara -> Barre la imagen con un rectángulo de tamaño apropiado y comprueba dónde da valores altos el detector

#### 1. Características de Haar

Tomando un área de la imagen:
	· Dividirla en regiones
	· Sumar/Restar las sumas de píxeles en cada una
	· Zonas claras Suman - Zonas oscuras Restan
Mediante un umbral permite detectar patrones en el área tomada

#### 2. Detectores Débiles en Cascada

- Se fija el umbral para que los Falsos Negativos ≈ 0 aunque los Falsos Positivos ≈ 30-40%
- Colocando los detectores en serie y Evaluando primero características más discriminantes se consigue que los Falsos Positivos ≈ 0 (Tasas Acierto > 90%)

#### 3. Evaluación Características de Haar

**Imagen Integral I(x,y) :**
Cada punto tiene la suma todos los píxeles que quedan Arriba y a la Izquierda

<img src="C:\Users\Pablo\Desktop\PIV\Capturas\imagenIntegralHaar.jpg" style="zoom: 67%;" />

<img src="C:\Users\Pablo\Desktop\PIV\Capturas\evaluacionCaracHaar.jpg">

## Reconocimiento de Objetos General

### Basados en Apariencia

- En base a un Modelo del objeto con diferentes parámetros se pueden generar las diferentes apariencias del objeto (Instancias)
- Se alinea el modelo con la imagen (Matching) para obtener el valor de los parámetros que que generan la apariencia del objeto en la imagen
- Se deben considerar los Cambios de Perspectiva, Color, Tamaño e Iluminación

### Basados en Características

- En base a Ejemplos se determinan las Características del objeto en diversas condiciones
- Las características se buscan en puntos interesantes: Esquinas, Blobs...
- Se construyen Descriptores Locales en base a esas características
- Se considera que el objeto está si hay suficientes características en posiciones coherentes

### Descriptor SIFT

- Detector de Blobs (pegotes de píxeles)
- Basado en Histogramas Locales de Orientación de Gradiente:
  Suma los gradientes en las distintas direcciones y los agrupa
  <img src="C:\Users\Pablo\Desktop\PIV\Capturas\sift.jpg">
- Útil para Alinear imágenes (Panorámicas) y encontrar Puntos de Referencia (Landmarks)
- Invariante a Traslación - Escalado - Rotación

### Espacio de Escalas y Detección de Blobs

· Introduce una 3ª dimensión en la imagen en base a un σ dado (escala) generando un volumen (x,y,σ) y se aplica una Convolución.

· Al aumentar σ la imagen se emborrona, produciendo que un objeto se convierta en un blob (mancha de un color sobre fondo de otro), entonces ese objeto se considera enfocado

· Para detectar el blob se aplican Diferencias de Gaussianas (DoG) - Aprox. de la 2ª Derivada

# Clasificación y Reconocimiento con Deep Learning

## Clasificación y Reconocimiento

- <u>Clasificación</u>: Separación de los datos en categorías
- Reconocimiento:
	- <u>Regresión</u>: Proporciona como salida números reales en lugar de categorías
	- Etiquetado de Secuencias
	- Análisis Sintácticos

## Red Neuronal

- <u>Red Neuronal</u>: Conjunto conectado de capas de neuronas

- <u>Neurona</u>:
· Conjunto de entradas Xi con pesos Wi asociados
· Función de activación f() proporciona la salida. Suele ser No-Lineal
<img src="C:\Users\Pablo\Desktop\PIV\Capturas\activacionNeurona.jpg">

## Neurona como Clasificador

- Considerando el Hiperespacio formado por los valores de entrada Xi, la neurona divide el Espacio de Características en 2 mitades.
- Esta división viene dada por los Pesos Wi y el Sesgo. Cada división corresponde a una categoría

## Clasificación con Redes Neuronales

En representaciones complejas se introducen Capas de Neuronas que transforman el espacio vectorial de entrada y hacen las clases más separables.

## Complejidad y Generalización

· Sistema Complejo -> Tiende a sobreaprender y No generaliza
· Sistema Simple -> Generaliza pero No funciona con representaciones complejas

## Entrenamiento de Redes Neuronales

### Entrenamiento

Una red está definida por su Topología y los Pesos de cada neurona.
- La mejor topología se encuentra probando distintas con el Conjunto de Validación
- El aprendizaje instancia los parámetros con el Conjunto de Entrenamiento

### Algoritmo Backpropagation

1. Calcula la salida de la red para una muestra concreta
2. Calcula la diferencia entre la salida obtenida y la esperada
3. Se actualizan los pesos hacia atrás en base a esa diferencia
	- La actualización es por pequeños lotes (batchs) y se realiza múltiples veces (epochs)

## Redes Convolucionales

- Como entrada toman datos N-Dimensionales
- Tienen neuronas que actúan como Máscaras de Convolución
- Tienen capas que Reducen el Tamaño de los Datos

<img src="C:\Users\Pablo\Desktop\PIV\Capturas\redConvolucional.jpg" style="zoom: 67%;" />

### Capas de Convolución

- Una neurona de convolución está asociada a una posición de la imagen y conectada con los píxeles del vecindario. Sus pesos son el juego de coeficientes de la máscara (filtro)
- Devuelve un volumen del Tamaño de la imagen y Profundidad el nº de Filtro aplicados

### Capas de Max Pooling

- Reducen el tamaño de la imagen tomando máximos por áreas
- Sin coeficientes que entrenar
- Compatible con Backpropagation

### Capas de Dropout

- Se eliminan neuronas aleatoriamente para evitar que se Sintonicen entre ellas (Coaprendizaje)
- Sin coeficientes que entrenar
- Reduce el tiempo de entrenamiento

### Capas de Batch Normalization

- Normalizan y regularizan los datos haciendo que estén en un rango aceptable
- La red optimiza este proceso de forma autónoma

## Tipos de Redes Profundas

- <u>Redes Recurrentes</u>: Análisis de secuencias
- <u>Wavenets</u>: Convolución 1D en Sonidos
- <u>Encoders y Decoders</u>: Comprimir, Representar imágenes
- <u>Redes Generativas y Adversarias</u>: Una genera y la otra discrimina
- <u>Long Short-Term Memory</u>: Procesamiento del lenguaje

## Identificación de Caras con Deep Learning

### Deep Face

1. Alineación de la Cara (Preprocesamiento)
	- Detección mediante Clasificadores Débiles (Haar)
	- Localización mediante Puntos Singulares (SIFT)
	- Estirado de la imagen (Frontalización)
2. Estructura:
	- 2 capas Convolucionales
	- 1 capa Max Pooling
	- 3 capas Localmente Conectadas (Convoluciones con distintos coeficientes)
	- 2 capas Totalmente Conectadas